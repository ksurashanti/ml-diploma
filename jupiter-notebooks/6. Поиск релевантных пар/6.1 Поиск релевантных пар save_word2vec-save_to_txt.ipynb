{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041a2335-f84c-46c8-9d7f-eaa61a6398c6",
   "metadata": {},
   "source": [
    "Есть датфрейм с authors, text, annotation и title. Текст предобработан, стоп-слова удалены. У одной статьи может быть несколько авторов, тогда они записаны в одной ячейке authors и разделены запятой. \n",
    "\n",
    "Функции:\n",
    "- для вычисления всех соавторов одного человека по ФИО, они могут быть записаны в разных ячейках датафрейма. \n",
    "\n",
    "- функция для векторизации текста.  \n",
    "\n",
    "- функция для вычисления коэффициента схожести.\n",
    "\n",
    "- функция для рекомендации новых соавторов. \n",
    "\n",
    "В функцию для рекомендации новых соавторов подаётся на вход ФИО автора. На выходе ФИО автора, названия всех статей в которых он участвовал, список его соавторов, список трёх рекомендуемых новых авторов/коллективов авторов, названия их статей и коэффициент близости. \n",
    "\n",
    "Ограничения:\n",
    "\n",
    "- Нельзя рекомендовать автора самому себе \n",
    "- Нельзя рекомендовать автору его текущих соавторов. \n",
    "\n",
    "Особенности:\n",
    "\n",
    "Необходимо предусмотреть ситуацию когда рекомендуется несколько человек, написавших одну и ту же статью, при совпадении коэффициента близости у новых соавторов необходимо объединять их ФИО через запятую, писать их общую статью один раз и на 2 и 3 месте писать новых рекомендуемых авторов. При совпадении 2 и 3 рекомендации также следует их объединять и на третье место выводить следующих по коэффициенту схожести коллектив авторов/автора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69a967a-a2af-4787-ba92-42d035d3c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pprint\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61969836-1e6c-4bad-b8fc-80020f94f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('date_it_lemm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2f2566-c10d-4eb4-b5fd-07d8fa089205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['authors'] = df['authors'].str.split(',') #авторов через запятую разделяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec293f1-4a84-423c-b0ae-12524c99bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthors(df, author_name):\n",
    "    coauthors = set()\n",
    "    for authors_list in df['authors'].str.split(', '):\n",
    "        if author_name in authors_list:\n",
    "            coauthors.update(authors_list)\n",
    "    coauthors.discard(author_name)  # удаляем самого автора\n",
    "    return list(coauthors)\n",
    "\n",
    "def calculate_similarity(tfidf_matrix, target_indices, all_indices):\n",
    "    similarities = cosine_similarity(tfidf_matrix[target_indices], tfidf_matrix[all_indices])\n",
    "    return similarities.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742156d6-e414-4dcf-affc-4ba44f211813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1d9ef309ee0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#модель Word2Vec\n",
    "def train_word2vec_model(texts, save_path='word2vec.model'):\n",
    "    sentences = [text.split() for text in texts]\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    model.save(save_path)  # Сохраняем модель на диск\n",
    "    return model\n",
    "\n",
    "texts = df['text'].tolist()  # Тексты для обучения\n",
    "train_word2vec_model(texts, save_path='word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a11b815e-84f2-4307-a6ab-3ed384a79ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec_model(load_path='word2vec.model'):\n",
    "    return Word2Vec.load(load_path)  # Загружаем модель с диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e47063e-1a71-47bc-be34-d3310fee86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text_with_word2vec(text, model):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)  #усреднение векторов\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  #нулевой вектор если слов нет\n",
    "\n",
    "def vectorize_texts_with_word2vec(df, text_column='text', model_path='word2vec.model'):\n",
    "    print(\"Загрузка модели Word2Vec...\")\n",
    "    word2vec_model = load_word2vec_model(model_path)\n",
    "    \n",
    "    print(\"Векторизация текстов...\")\n",
    "    vectors = df[text_column].apply(lambda x: vectorize_text_with_word2vec(x, word2vec_model))\n",
    "    \n",
    "    #список векторов в массив\n",
    "    return np.array(vectors.tolist()), word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc8be4aa-889f-436e-a7b3-3fff9ab4ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_new_coauthors(df, author_name, model_path='word2vec.model'):\n",
    "    target_mask = df['authors'].str.contains(author_name, regex=False)  #данные автора\n",
    "    target_indices = df[target_mask].index.tolist()\n",
    "    \n",
    "    if not target_indices:\n",
    "        return {\"error\": \"Автор не найден\"}\n",
    "    \n",
    "    current_coauthors = get_coauthors(df, author_name)  #текущие соавторы\n",
    "    \n",
    "    tfidf_matrix, _ = vectorize_texts_with_word2vec(df, text_column='text', model_path=model_path)\n",
    "    \n",
    "    all_indices = df.index.tolist()\n",
    "    similarities = calculate_similarity(tfidf_matrix, target_indices, all_indices)  # Схожести\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'index': all_indices,\n",
    "        'similarity': similarities,\n",
    "        'authors': df['authors'],\n",
    "        'title': df['title']\n",
    "    })\n",
    "    \n",
    "    results = results[\n",
    "        (results['similarity'] < 1.0) &  #исключаем статьи автора\n",
    "        (~results['authors'].isin([author_name]))  #исключаем соавторов\n",
    "    ]\n",
    "    \n",
    "    #группировка по коэффициенту схожести\n",
    "    grouped = results.groupby('similarity').agg({\n",
    "        'authors': lambda x: ', '.join(sorted(set(', '.join(x).split(', ')))),\n",
    "        'title': lambda x: ', '.join(sorted(set(x)))\n",
    "    }).reset_index().sort_values('similarity', ascending=False)\n",
    "    \n",
    "    recommendations = []\n",
    "    used_authors = set(current_coauthors + [author_name])  #формируем рекомендации\n",
    "    \n",
    "    for _, row in grouped.iterrows():\n",
    "        candidates = [a.strip() for a in row['authors'].split(',') if a.strip() not in used_authors]\n",
    "        if candidates:\n",
    "            unique_candidates = []\n",
    "            for candidate in candidates:\n",
    "                if candidate not in used_authors:\n",
    "                    unique_candidates.append(candidate)\n",
    "                    used_authors.add(candidate)\n",
    "            \n",
    "            if unique_candidates:\n",
    "                recommendations.append({\n",
    "                    'authors': ', '.join(unique_candidates),\n",
    "                    'titles': row['title'],\n",
    "                    'similarity': round(row['similarity'], 2)\n",
    "                })\n",
    "        \n",
    "        if len(recommendations) >= 3:\n",
    "            break\n",
    "    \n",
    "    output = {\n",
    "        \"Автор\": author_name,\n",
    "        \"Текущие соавторы\": current_coauthors,\n",
    "        \"Статьи\": df[target_mask]['title'].tolist(),\n",
    "        \"Рекомендуемые соавторы\": recommendations[:3]\n",
    "    }\n",
    "    \n",
    "    #результаты в файлы\n",
    "    save_results_to_txt(author_name, current_coauthors, output[\"Статьи\"], output[\"Рекомендуемые соавторы\"], df)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ab1e741-eb6d-46b2-8b93-83708b007548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_txt(author_name, current_coauthors, articles, recommendations, df):\n",
    "    #создаем папку\n",
    "    import os\n",
    "    if not os.path.exists(\"output\"):\n",
    "        os.makedirs(\"output\")\n",
    "\n",
    "    #файл 1: информация об авторе, его соавторах и нулевой статье\n",
    "    with open(f\"output/{author_name}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Автор: {author_name}\\n\")\n",
    "        f.write(f\"Соавторы: {', '.join(current_coauthors)}\\n\\n\")\n",
    "        \n",
    "        #статьи у автора\n",
    "        if articles:\n",
    "            try:\n",
    "                first_article = df[df['title'] == articles[0]].iloc[0]\n",
    "                f.write(f\"Заголовок: {first_article['title']}\\n\")\n",
    "                f.write(f\"Аннотация: {first_article['annotation']}\\n\")\n",
    "                f.write(f\"Текст: {first_article['text']}\\n\")\n",
    "            except IndexError:\n",
    "                f.write(\"Нулевая статья не найдена.\\n\")\n",
    "        else:\n",
    "            f.write(\"Статьи автора не найдены.\\n\")\n",
    "\n",
    "    #файлы 2-4: рекомендуемые статьи\n",
    "    for i, rec in enumerate(recommendations[:3], start=1):\n",
    "        with open(f\"output/{author_name}_recommendation_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Коэффициент схожести: {rec['similarity']}\\n\")\n",
    "            f.write(f\"Рекомендуемые авторы: {rec['authors']}\\n\\n\")\n",
    "            \n",
    "            titles = rec['titles'].split(', ')\n",
    "            for title in titles:\n",
    "                try:\n",
    "                    article = df[df['title'] == title].iloc[0]\n",
    "                    f.write(f\"Заголовок: {article['title']}\\n\")\n",
    "                    f.write(f\"Аннотация: {article['annotation']}\\n\")\n",
    "                    f.write(f\"Текст: {article['text']}\\n\\n\")\n",
    "                except IndexError:\n",
    "                    f.write(f\"Статья с заголовком '{title}' не найдена.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6720cb3a-47e0-48ef-85b7-84070ac1ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели Word2Vec...\n",
      "Векторизация текстов...\n",
      "{'Автор': 'Большаков А. О.',\n",
      " 'Рекомендуемые соавторы': [{'authors': 'Здитовец А. Л.',\n",
      "                             'similarity': 0.99,\n",
      "                             'titles': 'ОСНОВНЫЕ ТЕХНОЛОГИИ И ФРЕЙМВОРКИ ДЛЯ '\n",
      "                                       'БЕКЕНД-РАЗРАБОТКИ НА JAVA'},\n",
      "                            {'authors': 'Жидков Виталий Алексеевич',\n",
      "                             'similarity': 0.98,\n",
      "                             'titles': 'Сравнительный анализ SCADA-систем, '\n",
      "                                       'применяемых в диспетчерских службах '\n",
      "                                       'Белгородской энергосистемы'},\n",
      "                            {'authors': 'Массель Людмила Васильевна, Черноусов '\n",
      "                                        'Антон Владимирович',\n",
      "                             'similarity': 0.98,\n",
      "                             'titles': 'Интеграция унаследованных программных '\n",
      "                                       'комплексов в ИТ-инфраструктуру научных '\n",
      "                                       'исследований'}],\n",
      " 'Статьи': ['АВТОМАТИЗАЦИЯ ПРОЦЕССОВ МОНИТОРИНГА И ИНВЕНТАРИЗАЦИИ '\n",
      "            'ИНФОРМАЦИОННО-ТЕХНОЛОГИЧЕСКОЙ ИНФРАСТРУКТУРЫ, ПРИМЕНЯЕМОЙ В '\n",
      "            'УЧЕБНОМ ПРОЦЕССЕ'],\n",
      " 'Текущие соавторы': ['Леонтьев А. С.']}\n",
      "\n",
      " Статьи сохранены в папку output\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "rec_list = recommend_new_coauthors(df, 'Большаков А. О.', model_path='word2vec.model')\n",
    "pprint.pprint(rec_list)\n",
    "print('\\n Статьи сохранены в папку output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
