{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041a2335-f84c-46c8-9d7f-eaa61a6398c6",
   "metadata": {},
   "source": [
    "Есть датфрейм с authors, text, annotation и title. Текст предобработан, стоп-слова удалены. У одной статьи может быть несколько авторов, тогда они записаны в одной ячейке authors и разделены запятой. \n",
    "\n",
    "Функции:\n",
    "- для вычисления всех соавторов одного человека по ФИО, они могут быть записаны в разных ячейках датафрейма. \n",
    "\n",
    "- функция для векторизации текста.  \n",
    "\n",
    "- функция для вычисления коэффициента схожести.\n",
    "\n",
    "- функция для рекомендации новых соавторов. \n",
    "\n",
    "В функцию для рекомендации новых соавторов подаётся на вход ФИО автора. На выходе ФИО автора, названия всех статей в которых он участвовал, список его соавторов, список трёх рекомендуемых новых авторов/коллективов авторов, названия их статей и коэффициент близости. \n",
    "\n",
    "Ограничения:\n",
    "\n",
    "- Нельзя рекомендовать автора самому себе \n",
    "- Нельзя рекомендовать автору его текущих соавторов. \n",
    "\n",
    "Особенности:\n",
    "\n",
    "Необходимо предусмотреть ситуацию когда рекомендуется несколько человек, написавших одну и ту же статью, при совпадении коэффициента близости у новых соавторов необходимо объединять их ФИО через запятую, писать их общую статью один раз и на 2 и 3 месте писать новых рекомендуемых авторов. При совпадении 2 и 3 рекомендации также следует их объединять и на третье место выводить следующих по коэффициенту схожести коллектив авторов/автора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e69a967a-a2af-4787-ba92-42d035d3c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pprint\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61969836-1e6c-4bad-b8fc-80020f94f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('date_it_lemm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e2f2566-c10d-4eb4-b5fd-07d8fa089205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['authors'] = df['authors'].str.split(',') #авторов через запятую разделяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eec293f1-4a84-423c-b0ae-12524c99bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Функция для обучения модели Word2Vec на текстах из датафрейма\n",
    "def train_word2vec_model(texts):\n",
    "    # Разбиваем тексты на слова\n",
    "    sentences = [text.split() for text in texts]\n",
    "    \n",
    "    # Обучаем модель Word2Vec\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return model\n",
    "\n",
    "# Функция для векторизации текста с использованием Word2Vec\n",
    "def vectorize_text_with_word2vec(text, model):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)  # Усредняем векторы слов\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Возвращаем нулевой вектор, если слова не найдены\n",
    "\n",
    "# Функция для векторизации всех текстов в датафрейме\n",
    "def vectorize_texts_with_word2vec(df, text_column='text'):\n",
    "    # Обучаем модель Word2Vec на текстах из датафрейма\n",
    "    print(\"Обучение модели Word2Vec...\")\n",
    "    word2vec_model = train_word2vec_model(df[text_column])\n",
    "    \n",
    "    # Векторизация текстов\n",
    "    print(\"Векторизация текстов...\")\n",
    "    vectors = df[text_column].apply(lambda x: vectorize_text_with_word2vec(x, word2vec_model))\n",
    "    \n",
    "    # Преобразуем список векторов в массив\n",
    "    return np.array(vectors.tolist()), word2vec_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc8be4aa-889f-436e-a7b3-3fff9ab4ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_new_coauthors(df, author_name):\n",
    "    target_mask = df['authors'].str.contains(author_name, regex=False)  # Данные автора\n",
    "    target_indices = df[target_mask].index.tolist()\n",
    "    \n",
    "    if not target_indices:\n",
    "        return {\"error\": \"Автор не найден\"}\n",
    "    \n",
    "    current_coauthors = get_coauthors(df, author_name)  # Текущие соавторы\n",
    "    \n",
    "    # Векторизация текстов с помощью Word2Vec\n",
    "    tfidf_matrix, _ = vectorize_texts_with_word2vec(df, text_column='text')\n",
    "    \n",
    "    all_indices = df.index.tolist()\n",
    "    similarities = calculate_similarity(tfidf_matrix, target_indices, all_indices)  # Схожести\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'index': all_indices,\n",
    "        'similarity': similarities,\n",
    "        'authors': df['authors'],\n",
    "        'title': df['title']\n",
    "    })\n",
    "    \n",
    "    results = results[\n",
    "        (results['similarity'] < 1.0) &  # Исключаем статьи автора\n",
    "        (~results['authors'].isin([author_name]))  # Исключаем соавторов\n",
    "    ]\n",
    "    \n",
    "    # Группировка по коэффициенту схожести\n",
    "    grouped = results.groupby('similarity').agg({\n",
    "        'authors': lambda x: ', '.join(sorted(set(', '.join(x).split(', ')))),\n",
    "        'title': lambda x: ', '.join(sorted(set(x)))\n",
    "    }).reset_index().sort_values('similarity', ascending=False)\n",
    "    \n",
    "    recommendations = []\n",
    "    used_authors = set(current_coauthors + [author_name])  # Формируем рекомендации\n",
    "    \n",
    "    for _, row in grouped.iterrows():\n",
    "        candidates = [a.strip() for a in row['authors'].split(',') if a.strip() not in used_authors]\n",
    "        if candidates:\n",
    "            unique_candidates = []\n",
    "            for candidate in candidates:\n",
    "                if candidate not in used_authors:\n",
    "                    unique_candidates.append(candidate)\n",
    "                    used_authors.add(candidate)\n",
    "            \n",
    "            if unique_candidates:\n",
    "                recommendations.append({\n",
    "                    'authors': ', '.join(unique_candidates),\n",
    "                    'titles': row['title'],\n",
    "                    'similarity': round(row['similarity'], 2)\n",
    "                })\n",
    "        \n",
    "        if len(recommendations) >= 3:\n",
    "            break\n",
    "    \n",
    "    # Итоговый вывод\n",
    "    output = {\n",
    "        \"Автор\": author_name,\n",
    "        \"Текущие соавторы\": current_coauthors,\n",
    "        \"Статьи\": df[target_mask]['title'].tolist(),\n",
    "        \"Рекомендуемые соавторы\": recommendations[:3]\n",
    "    }\n",
    "#    save_results_to_txt(author_name, current_coauthors, output[\"Статьи\"], output[\"Рекомендуемые соавторы\"], df)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6720cb3a-47e0-48ef-85b7-84070ac1ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели Word2Vec...\n",
      "Векторизация текстов...\n",
      "{'Автор': 'Большаков А. О.',\n",
      " 'Рекомендуемые соавторы': [{'authors': 'Здитовец А. Л.',\n",
      "                             'similarity': 0.99,\n",
      "                             'titles': 'ОСНОВНЫЕ ТЕХНОЛОГИИ И ФРЕЙМВОРКИ ДЛЯ '\n",
      "                                       'БЕКЕНД-РАЗРАБОТКИ НА JAVA'},\n",
      "                            {'authors': 'Жидков Виталий Алексеевич',\n",
      "                             'similarity': 0.98,\n",
      "                             'titles': 'Сравнительный анализ SCADA-систем, '\n",
      "                                       'применяемых в диспетчерских службах '\n",
      "                                       'Белгородской энергосистемы'},\n",
      "                            {'authors': 'Массель Людмила Васильевна, Черноусов '\n",
      "                                        'Антон Владимирович',\n",
      "                             'similarity': 0.98,\n",
      "                             'titles': 'Интеграция унаследованных программных '\n",
      "                                       'комплексов в ИТ-инфраструктуру научных '\n",
      "                                       'исследований'}],\n",
      " 'Статьи': ['АВТОМАТИЗАЦИЯ ПРОЦЕССОВ МОНИТОРИНГА И ИНВЕНТАРИЗАЦИИ '\n",
      "            'ИНФОРМАЦИОННО-ТЕХНОЛОГИЧЕСКОЙ ИНФРАСТРУКТУРЫ, ПРИМЕНЯЕМОЙ В '\n",
      "            'УЧЕБНОМ ПРОЦЕССЕ'],\n",
      " 'Текущие соавторы': ['Леонтьев А. С.']}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Пример вызова функции\n",
    "rec_list = recommend_new_coauthors(df, 'Большаков А. О.')\n",
    "pprint.pprint(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14350814-1c8b-4030-8ee9-ae775058d68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
